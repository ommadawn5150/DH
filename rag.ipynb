{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "\n",
    "# For download embeddings model\n",
    "from huggingface_hub import snapshot_download\n",
    "\n",
    "# For embeddings and vector stores\n",
    "from langchain_huggingface.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.indexes import VectorstoreIndexCreator\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.vectorstores import Chroma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_model_name = \"intfloat/multilingual-e5-large-instruct\"\n",
    "embeddings_path = f\"./embedding_model/{embeddings_model_name}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract txts from Website\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4\n",
    "import requests\n",
    "\n",
    "url = 'https://home.cern'\n",
    "response = requests.get(url)\n",
    "soup = bs4.BeautifulSoup(response.text, 'html.parser')\n",
    "links = soup.find_all('a')\n",
    "links = [link.get('href') for link in links if link.get('href') is not None]\n",
    "urls = []\n",
    "for l in links:\n",
    "    if l.startswith('/science') :\n",
    "        if l not in urls:\n",
    "            urls.append(url + l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import langchain_community.document_loaders\n",
    "\n",
    "loader = langchain_community.document_loaders.UnstructuredURLLoader(\n",
    "    urls=urls\n",
    ")\n",
    "with open(\"loader.pkl\", \"wb\") as f:\n",
    "    pickle.dump(loader, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"loader.pkl\", \"rb\") as f:\n",
    "    loader = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DB establishment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download the embeddigns model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/masahirotojo/Documents/DH/venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:1204: UserWarning: `local_dir_use_symlinks` parameter is deprecated and will be ignored. The process to download files to a local folder has been updated and do not rely on symlinks anymore. You only need to pass a destination folder as`local_dir`.\n",
      "For more details, check out https://huggingface.co/docs/huggingface_hub/main/en/guides/download#download-files-to-local-folder.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "547366eaedaa4fa3a0ccd0b9d5c76c7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 18 files:   0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81ba30fdbea54e15986a60daf67ea958",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/690 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f880321de284987879b0ea18bf6a724",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "1_Pooling/config.json:   0%|          | 0.00/271 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfb3ecb0adad41f8b7fb2630e8e217a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/140k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d23ee1d66a842d890a33ca92a6c8bc3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b52c34e0d8444b78b0124631ab93aa23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/128 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bb0581192af42faaada283a1b4bee7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       ".gitattributes:   0%|          | 0.00/1.63k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca41bff02d6e4a0fb778c326a7929968",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "onnx/config.json:   0%|          | 0.00/763 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a09cb6ebb69485690100151ef0e511a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.12G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eedddc5f27414a34b5fd9fe527ecd325",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5017ac5499bd4a0d8efe2a84df863e40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/17.1M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0a7f99e82374434a4af45eb35317fd4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "onnx/special_tokens_map.json:   0%|          | 0.00/964 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a125bb3aca3d44448f6b01a536fcd1f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.onnx:   0%|          | 0.00/686k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4b5bda9857046a9857ad58783368570",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07cf676c655644cea9b2de305f738326",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "onnx/tokenizer_config.json:   0%|          | 0.00/1.18k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7f820a699ea449eb17b05f6fd6c855e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.onnx_data:   0%|          | 0.00/2.24G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16ce727b014841bbb0d2eb7056716868",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/964 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8011c7d1cd02408f9cd14144600ae46a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/1.18k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd2127ed480847f4905b72a4da88eb11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/17.1M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if os.path.isfile(f\"embedding_model/{embeddings_model_name}/config.json\"):\n",
    "    print(\"Model already exists.\")\n",
    "else:\n",
    "    download_path = snapshot_download(\n",
    "        repo_id=embeddings_model_name,\n",
    "        local_dir = f\"embedding_model/{embeddings_model_name}\",\n",
    "        local_dir_use_symlinks=False # If you want to use symlinks, set this to True\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 550, which is longer than the specified 512\n",
      "Created a chunk of size 565, which is longer than the specified 512\n",
      "Created a chunk of size 771, which is longer than the specified 512\n",
      "Created a chunk of size 552, which is longer than the specified 512\n",
      "Created a chunk of size 586, which is longer than the specified 512\n",
      "Created a chunk of size 617, which is longer than the specified 512\n",
      "Created a chunk of size 586, which is longer than the specified 512\n",
      "Created a chunk of size 584, which is longer than the specified 512\n",
      "Created a chunk of size 826, which is longer than the specified 512\n",
      "Created a chunk of size 805, which is longer than the specified 512\n",
      "Created a chunk of size 575, which is longer than the specified 512\n",
      "Created a chunk of size 926, which is longer than the specified 512\n",
      "Created a chunk of size 999, which is longer than the specified 512\n",
      "Created a chunk of size 713, which is longer than the specified 512\n",
      "Created a chunk of size 1203, which is longer than the specified 512\n",
      "Created a chunk of size 699, which is longer than the specified 512\n",
      "Created a chunk of size 1554, which is longer than the specified 512\n",
      "Created a chunk of size 641, which is longer than the specified 512\n",
      "Created a chunk of size 544, which is longer than the specified 512\n",
      "Created a chunk of size 617, which is longer than the specified 512\n",
      "Created a chunk of size 727, which is longer than the specified 512\n",
      "Created a chunk of size 660, which is longer than the specified 512\n",
      "Created a chunk of size 609, which is longer than the specified 512\n",
      "Created a chunk of size 554, which is longer than the specified 512\n",
      "Created a chunk of size 637, which is longer than the specified 512\n",
      "Created a chunk of size 771, which is longer than the specified 512\n",
      "Created a chunk of size 552, which is longer than the specified 512\n",
      "Created a chunk of size 721, which is longer than the specified 512\n",
      "Created a chunk of size 727, which is longer than the specified 512\n",
      "Created a chunk of size 660, which is longer than the specified 512\n",
      "Created a chunk of size 519, which is longer than the specified 512\n",
      "Created a chunk of size 513, which is longer than the specified 512\n",
      "Created a chunk of size 566, which is longer than the specified 512\n",
      "Created a chunk of size 655, which is longer than the specified 512\n",
      "Created a chunk of size 531, which is longer than the specified 512\n",
      "Created a chunk of size 793, which is longer than the specified 512\n",
      "Created a chunk of size 533, which is longer than the specified 512\n",
      "Created a chunk of size 536, which is longer than the specified 512\n",
      "Created a chunk of size 771, which is longer than the specified 512\n",
      "Created a chunk of size 519, which is longer than the specified 512\n",
      "Created a chunk of size 567, which is longer than the specified 512\n",
      "Created a chunk of size 752, which is longer than the specified 512\n",
      "Created a chunk of size 556, which is longer than the specified 512\n",
      "Created a chunk of size 642, which is longer than the specified 512\n",
      "Created a chunk of size 557, which is longer than the specified 512\n",
      "Created a chunk of size 537, which is longer than the specified 512\n",
      "Created a chunk of size 567, which is longer than the specified 512\n",
      "Created a chunk of size 752, which is longer than the specified 512\n",
      "Created a chunk of size 679, which is longer than the specified 512\n",
      "Created a chunk of size 714, which is longer than the specified 512\n",
      "Created a chunk of size 681, which is longer than the specified 512\n",
      "Created a chunk of size 517, which is longer than the specified 512\n",
      "Created a chunk of size 806, which is longer than the specified 512\n",
      "Created a chunk of size 538, which is longer than the specified 512\n",
      "Created a chunk of size 679, which is longer than the specified 512\n",
      "Created a chunk of size 714, which is longer than the specified 512\n",
      "Created a chunk of size 681, which is longer than the specified 512\n",
      "Created a chunk of size 771, which is longer than the specified 512\n",
      "Created a chunk of size 552, which is longer than the specified 512\n",
      "Created a chunk of size 771, which is longer than the specified 512\n",
      "Created a chunk of size 552, which is longer than the specified 512\n",
      "Created a chunk of size 586, which is longer than the specified 512\n",
      "Created a chunk of size 586, which is longer than the specified 512\n",
      "Created a chunk of size 550, which is longer than the specified 512\n",
      "Created a chunk of size 550, which is longer than the specified 512\n",
      "Created a chunk of size 565, which is longer than the specified 512\n",
      "Created a chunk of size 565, which is longer than the specified 512\n"
     ]
    }
   ],
   "source": [
    "text_splitter = CharacterTextSplitter(\n",
    "    separator = \"\\n\",\n",
    "    chunk_size = 512,\n",
    "    chunk_overlap = 32,\n",
    "    length_function = len,\n",
    ")\n",
    "\n",
    "docs = text_splitter.split_documents(docs)\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=embeddings_path\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = FAISS.from_documents(docs, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = db.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"retriever.pkl\", \"wb\") as f:\n",
    "    pickle.dump(retriever, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt Template Created\n",
      "input_variables=['context', 'question', 'source'] input_types={} partial_variables={} template=\"\\n        <|system|>\\n        Use the following pieces of context to answer the question at the end. : {context}\\n        And you need to answer with following engagements;\\n            - If you don't know the answer, just say that you don't know, don't try to make up an answer.\\n            - Use markdown formatting when displaying code.\\n            - Emphasis should be used to terminologies.\\n            - Give sources you used at the end.\\n            - Answer in Japanese.\\n        </s>\\n        <|user|>\\n        {question}\\n        </s>\\n        {source}\\n    \"\n"
     ]
    }
   ],
   "source": [
    "from helpers import LLM\n",
    "llm = LLM()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Trained RAG Answer\n",
       "LHCは、素粒子を衝突させることで、素粒子の性質を研究するための装置です。LHCは、プロトンを高速で衝突させることで、素粒子の生成と相互作用を研究します。この衝突で生成される多くのquarkは、すぐに他の形態に崩壊します。LHCbは、b quarkを捉えるために、LHCのビームの軌道近くに高度な可動式トラッキングデテクターを開発しました。\n",
       "\n",
       "LHCは、ATLAS、CMS、LHCb、TOTEM、LHCf、MoEDAL-MAPP、FASER、SND@LHC、Fixed-target experimentsなどの多くの実験装置が設置されています。各実験装置は、異なる研究対象に焦点を当てています。\n",
       "\n",
       "LHCは、素粒子の研究のための世界的な協力プロジェクトです。LHCは、CERN（欧州核研究機構）が運営しています。\n",
       "\n",
       "Sources:\n",
       "- https://home.cern/science/experiments\n",
       "- https://home.cern/science/experiments\n",
       "- https://home.cern/science/experiments\n",
       "- https://home.cern/science/experiments/lhcb"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "question = \"LHCで何が起こっているのですか？\"\n",
    "response = llm.chat(question, retriever=retriever)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
